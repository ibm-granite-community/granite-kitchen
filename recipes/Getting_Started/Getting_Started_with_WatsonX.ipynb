{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Quickstart: Using IBM Granite on IBM watsonx.ai\n",
    "\n",
    "This notebook is a step-by-step tutorial for running **Granite** models on **IBM watsonx.ai** from your Jupyter environment. It covers prerequisites, how to get your credentials and project set up in IBM Cloud, local installation, environment configuration, choosing the right model, and a minimal \"Hello World\" via both the **ibm-watsonx-ai** SDK and **LangChain**.\n",
    "\n",
    "**What you'll do:**\n",
    "1. Complete IBM Cloud prerequisites (account setup, API key, watsonx.ai project).\n",
    "2. Install the required Python packages.\n",
    "3. Choose a **Granite** model (e.g., `granite-3-3-8b-instruct`).\n",
    "4. Make a generation request with the **IBM SDK**.\n",
    "5. Make the same request via **LangChain**.\n",
    "\n",
    "> References: [watsonx.ai foundation model catalog](https://www.ibm.com/products/watsonx-ai/foundation-models), [Granite 3.3 docs](https://www.ibm.com/granite/docs/models/granite/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 0) Prerequisites\n",
    "\n",
    "Before running any code here, complete these steps in IBM Cloud:\n",
    "\n",
    "### Create / sign in to an IBM Cloud account and provision watsonx.ai.  \n",
    "   - Go to [IBM Cloud](https://cloud.ibm.com) and sign up or log in with your IBM ID.\n",
    "   - If you’re new, you can start with a Lite plan or apply a promo code for free credits.\n",
    "   - Create a watsonx.ai service instance from your IBM Cloud dashboard. This provides access to [IBM foundation models](https://www.ibm.com/products/watsonx-ai/foundation-models).\n",
    "   - After login, navigate to the IBM watsonx.ai service from the IBM Cloud Catalog. You can also create a watsonx.ai free trial by following these [instructions](https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/signup-wx.html?context=wx&audience=wdp#personal).\n",
    "   - Go to Catalog and select the `AI & Machine Learning` option. Next, choose `watsonx.ai`.\n",
    "\n",
    "   ![IBMCloud](./recordings/ibm-cloud-wx-launch.gif \"segment\")\n",
    "\n",
    "### Create a watsonx.ai Project\n",
    "   A watsonx.ai project is a collaborative workspace within IBM's [watsonx.ai](https://dataplatform.cloud.ibm.com/wx/home?context=wx) platform, where teams build, train, tune, and deploy both generative AI and traditional machine learning models. A project in watsonx.ai acts as a shared environment for data scientists, developers, and other collaborators.\n",
    "\n",
    "   ![WXProjectCreation](./recordings/wx-create-new-project.gif \"segment\")\n",
    "\n",
    "   - On the watsonx.ai console, click on `Projects` and select `View all projects` and choose a [New project](https://dataplatform.cloud.ibm.com/projects/new-project?context=wx).\n",
    "   - Choose:\n",
    "      - Empty project (start from scratch), or\n",
    "      - Sample project (with preloaded assets), or\n",
    "      - Import project (upload a .zip from another environment).\n",
    "   - Name your project (must be unique, 1–255 chars, no %, \\\\, or leading/trailing spaces).\n",
    "   - Storage requirement: Associate an IBM Cloud Object Storage instance (create one if you don’t have it).\n",
    "   - Click Create. Your project now has:\n",
    "      - A unique Project ID (needed for API calls).\n",
    "      - A dedicated storage bucket for assets.\n",
    "   - Note your service **URL** (region endpoint), e.g., `https://us-south.ml.cloud.ibm.com`.\n",
    "\n",
    "   For working with existing projects, see here:\n",
    "   ![WXProjectAccess](./recordings/wx-open-existing-project.gif \"segment\")\n",
    "\n",
    "### Associate Watson Machine Learning Service\n",
    "   Watson Machine Learning provides a full range of tools and services, so you can build, train, and deploy Machine Learning models.\n",
    "\n",
    "   - Open your project, in WML and click on `Manage` at the top nav bar selecting `Services and Integrations`.\n",
    "   - Click `Associate Service` and choose `Watson Machine Learning (WML)`. Note: You must have Admin role in project.\n",
    "   - If you don’t have a WML instance:\n",
    "      - Go to IBM Cloud Catalog, select Watson Machine Learning.\n",
    "      - Create an instance in the same region as your project.\n",
    "      - Once created, link the WML instance to your project.\n",
    "      - This step is required for running foundation models and APIs.\n",
    "\n",
    "   ![AssociateWML](./recordings/associate-wml.gif \"segment\")\n",
    "\n",
    "### Obtain Your Credentials\n",
    "   - In IBM Cloud, go to Manage option and select `Access (IAM)` and choose [API keys](https://cloud.ibm.com/iam/apikeys).\n",
    "   - Create an API key (or use an existing one).\n",
    "   - Download or copy your key immediately (cannot see again after creation).\n",
    "   - Note:\n",
    "      - API Key : this is used for authentication.\n",
    "      - Service URL. E.g., https://us-south.ml.cloud.ibm.com.\n",
    "      - Project ID. This can be obtained from your watsonx.ai project details. In watsonx.ai, open the left menu and select `Projects` > `View all projects`. Select your desired project.\n",
    "      - Go to Manage tab, click on General. Don't forget to copy Project ID for later.\n",
    "         - You should see Watson Machine Learning listed under Services for your project.\n",
    "         - These three values (API_KEY, URL, PROJECT_ID) are required for SDK and LangChain integration.\n",
    "         - See: [Credentials for programmatic access](https://www.ibm.com/docs/en/watsonx/saas?topic=resources-credentials-programmatic-access). \n",
    "\n",
    "   ![IAMKey](./recordings/iam-key-demo.gif \"segment\")\n",
    "\n",
    "### Validate Access\n",
    "   -  Ensure your IBM Cloud user has Editor role for watsonx.ai and WML services.\n",
    "   - If you plan to use APIs directly, confirm you can generate a [Bearer token](https://cloud.ibm.com/docs/account?topic=account-iamtoken_from_apikey) using your API key.\n",
    "\n",
    "### (Optional) In **Resource hub** or **Prompt Lab**: \n",
    "   The Watsonx Prompt Lab is a tool within IBM's watsonx.ai platform that allows users to experiment with, test, and refine prompts for various large language models (LLMs).\n",
    "\n",
    "   - Review Granite 3.3 models and copy the exact **`model_id`**. You can also list available models via API (shown later).  \n",
    "   - See: [Get foundation model information / model IDs](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-api-model-ids.html?context=wx&audience=wdp).\n",
    "\n",
    "> You will paste **three values** into this notebook: `WATSONX_URL`, `WATSONX_APIKEY`, and `WATSONX_PROJECT_ID`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1) Choosing a Granite model\n",
    "\n",
    "The Granite models available on watsonx are listed on the [Resource Hub](https://dataplatform.cloud.ibm.com/samples?context=wx&tab=foundation-model&query=granite). For more information about Granite models on watsonx, see [Foundation models](https://www.ibm.com/products/watsonx-ai/foundation-models) on watsonx.ai.\n",
    "\n",
    "| Model Type | Model IDs | Best For | Notes |\n",
    "|------------|-----------|----------|-------|\n",
    "| **Instruct** | `granite-3-3-2b-instruct`, `granite-3-3-8b-instruct` | Chat, Q&A, reasoning, summaries, coding | Use **8B** for higher quality; **2B** is faster and cheaper |\n",
    "| **Base**    | `granite-3-3-2b-base`, `granite-3-3-8b-base`         | Fine-tuning, advanced prompting         | Pre-trained only; not instruction-tuned |\n",
    "\n",
    "**Context Support**: All Granite 3.3 models support up to **128K tokens**.\n",
    "\n",
    "\n",
    "> ⚠️ Availability can be **region-specific**; if a model isn’t found, check your region’s catalog or list models via API (Section 4).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2) Install packages locally\n",
    "\n",
    "Run the next cell to install the SDKs and helpers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install ibm-watsonx-ai langchain langchain-ibm git+https://github.com/ibm-granite-community/utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 3) Configure your local environment\n",
    "\n",
    "Set the required settings as environment variables for this session. (You can also facilitate reuse across sessions, by maintaining an `.env` file in you local execution.)\n",
    "\n",
    "You need to provide to WatsonxLLM three values which are specific to your configuration:\n",
    "\n",
    "1. `WATSONX_PROJECT_ID` - the ID of the project you have associated to the WatsonMachineLearning service.\n",
    "2. `WATSONX_URL` - the endpoint which is applicable to your watsonx instance. More details on developer access can be found [here](https://dataplatform.cloud.ibm.com/developer-access?context=wx).\n",
    "3. `WATSONX_APIKEY` - the key which authenticates your request\n",
    "To access all three, go to your [watsonx dashboard](https://dataplatform.cloud.ibm.com/) and scroll down to Developer Access.\n",
    "\n",
    "Pick your project from the dropdown and the UI will provide both the Project ID and the watsonx.ai URL.\n",
    "\n",
    "There are also options to either create a new API key or manage existing ones.\n",
    "\n",
    "More in-depth instructions around API keys can be found in [this document](https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 4) Hello World with the **ibm-watsonx-ai** SDK\n",
    "\n",
    "A minimal generation call with a Granite 3.3 Instruct model.  \n",
    "Docs: [ibm-watsonx-ai Python library](https://www.ibm.com/docs/en/watsonx/saas?topic=resources-python-library)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_granite_community.notebook_utils import get_env_var\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "\n",
    "params = {\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.9,\n",
    "    \"max_tokens\": 128,\n",
    "}\n",
    "\n",
    "creds = Credentials(\n",
    "    url=get_env_var(\"WATSONX_URL\"),\n",
    "    api_key=get_env_var(\"WATSONX_APIKEY\"),\n",
    ")\n",
    "\n",
    "chat = ModelInference(\n",
    "    model_id=\"ibm/granite-3-3-8b-instruct\",  # set to 2B if desired\n",
    "    credentials=creds,\n",
    "    project_id=get_env_var(\"WATSONX_PROJECT_ID\"),\n",
    "    params=params,\n",
    ")\n",
    "\n",
    "# Chat-style messages\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Say hello to the world in one short sentence.\"}\n",
    "]\n",
    "\n",
    "result = chat.chat(messages=messages)\n",
    "\n",
    "try:\n",
    "    print(\"\\n--- Assistant ---\\n\")\n",
    "    print(result[\"choices\"][0][\"message\"][\"content\"])\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 5) Hello World with **LangChain**\n",
    "\n",
    "LangChain’s `ChatWatsonx` wrapper uses your watsonx **URL**, **project_id**, and **model_id**.  \n",
    "Docs: [LangChain watsonx integration](https://python.langchain.com/docs/integrations/llms/ibm_watsonx/), [langchain-ibm (PyPI)](https://pypi.org/project/langchain-ibm/), [ChatWatsonx](https://python.langchain.com/api_reference/ibm/chat_models/langchain_ibm.chat_models.ChatWatsonx.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_granite_community.notebook_utils import get_env_var\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.utils.utils import convert_to_secret_str\n",
    "from langchain_ibm.chat_models import ChatWatsonx\n",
    "\n",
    "# Set decoding parameters\n",
    "model_parameters = {\n",
    "    \"decoding_method\": \"sample\",\n",
    "    \"max_new_tokens\": 64,\n",
    "    \"min_new_tokens\": 1,\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 1.0,\n",
    "}\n",
    "\n",
    "# Initialize ChatWatsonx\n",
    "llm = ChatWatsonx(\n",
    "    model_id=\"ibm/granite-3-3-8b-instruct\",\n",
    "    url=convert_to_secret_str(get_env_var(\"WATSONX_URL\")),\n",
    "    apikey=convert_to_secret_str(get_env_var(\"WATSONX_APIKEY\")),\n",
    "    project_id=get_env_var(\"WATSONX_PROJECT_ID\"),\n",
    "    params=model_parameters,\n",
    ")\n",
    "\n",
    "# Use ChatPromptTemplate with HumanMessage\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  HumanMessage(\"Hello, world! Pretend you're a robot greeting humans for the first time. What would you say?\")\n",
    "])\n",
    "\n",
    "# LangChain pipeline\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Invoke the chain\n",
    "print(chain.invoke({}))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
