{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Getting Started with IBM watsonx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "This notebook demonstrates issuing inference calls against a model hosted remotely on [watsonx](https://www.ibm.com/products/watsonx-ai)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Install dependencies\n",
    "\n",
    "> **NOTE**: When running this recipe in [Colab](https://colab.research.google.com/), you may see an error about dependency conflicts with `google-colab 1.0.0`. You can safely ignore this error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/ibm-granite-community/utils \\\n",
    "    langchain_ibm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Accessing the Watson Machine Learning service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Establish a watsonx.ai Instance\n",
    "\n",
    "To use this remote option, create a watsonx.ai free trial by following [these instructions](https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/signup-wx.html?context=wx&audience=wdp#personal).\n",
    "\n",
    "If you don't already, you will need an IBM Cloud account which is included in the instructions.\n",
    "\n",
    "**Note:** You can now login to IBM Cloud with a Google account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Create a Watsonx.ai Project\n",
    "\n",
    "Once [watsonx](https://dataplatform.cloud.ibm.com/wx/home) is launched, scroll down to projects and create a new one. \n",
    "\n",
    "Give it an appropriate name and click create. The project should automatically open if succesfully created.\n",
    "\n",
    "**Note:** A sandbox project may have been setup by default during the creation of the watsonx.ai instance which can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Associate a Watson Machine Learning Service Under Your Project\n",
    "\n",
    "You'll need to connect a service to your project to process your requests.\n",
    "\n",
    "Inside the project, navigate to the `Manage` tab and then `Services and integrations` from the sidebar. Under `IBM Services`, select `Associate Services`. Select `WatsonMachineLearning` and confirm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Get the Necessary Credentials\n",
    "\n",
    "You need to provide to `WatsonxLLM` three values which are specific to your configuration:\n",
    " 1. `WATSONX_PROJECT_ID` - the ID of the project you have associated to the WatsonMachineLearning service\n",
    " 2. `WATSONX_URL` - the endpoint which is applicable to your watsonx instance\n",
    " 3. `WATSONX_APIKEY` - the key which authenticates your request\n",
    "\n",
    "To access all three, go to your [watsonx dashboard](https://dataplatform.cloud.ibm.com/) and scroll down to `Developer Access`.\n",
    "\n",
    "Pick your project from the dropdown and the UI will provide both the Project ID and the watsonx.ai URL.\n",
    "\n",
    "There are also options to either create a new API key or manage existing ones.\n",
    "\n",
    "More in-depth instructions around API keys can be found in [this document](https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Provide the Environment Variables\n",
    "\n",
    "There are three ways to provide the environment variables required by the `WatsonxLLM` client below. In order of precedence:\n",
    "\n",
    "1. Directly as an environment variable in the python environment where the jupyter notebook is running.\n",
    "2. As a Google Colab secret, if you are running the notebook in Colab.\n",
    "3. Supplied by the user in a prompt during execution of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Querying the LLM with Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Choose a model\n",
    "\n",
    "The Granite models available on watsonx are listed on the [Resource Hub](https://dataplatform.cloud.ibm.com/samples?context=wx&tab=foundation-model&query=granite). For more information about Granite models on watsonx, see [Foundation models on watsonx.ai](https://www.ibm.com/products/watsonx-ai/foundation-models).\n",
    "\n",
    "[`ibm/granite-3-3-8b-instruct`](https://dataplatform.cloud.ibm.com/wx/samples/models/ibm/granite-3-3-8b-instruct?context=wx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"ibm/granite-3-3-8b-instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Instantiate the model client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ibm_granite_community.notebook_utils import get_env_var\n",
    "from langchain_ibm import WatsonxLLM\n",
    "\n",
    "model = WatsonxLLM(\n",
    "    model_id=model_id,\n",
    "    url= get_env_var(\"WATSONX_URL\"),\n",
    "    apikey=get_env_var(\"WATSONX_APIKEY\"),\n",
    "    project_id=get_env_var(\"WATSONX_PROJECT_ID\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Perform inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\\\n",
    "<|start_of_role|>user<|end_of_role|>\\\n",
    "Tell a story about a duck who likes french fries.<|end_of_text|>\n",
    "<|start_of_role|>assistant<|end_of_role|>\"\"\"\n",
    "\n",
    "response = model.invoke(prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
